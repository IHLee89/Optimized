# 컴퓨터 하드웨어 최적화
- 컴퓨터 구조는 매우 다양하기 때문에 하드웨어 작동에 관한 엄격한 규칙을 정하기 어렵다.
- 많은 개발자는 자신의 코드가 어떤 프로세서에 의해 실행될지 조차 정확하게 알지 못하여 경험에 비추어 어림짐작한다.
***
## 2.1 C++은 컴퓨터의 거짓말을 믿습니다.
- C++ 프로그램의 명령문을 '순서대로 실행하는 것처럼' 작동하기만 하면 된다.  
  C++ 컴파일러와 컴퓨터 자체는 계산의 의미가 변경되지 않는 선에서 실행 순서를 변경하여 프로그램 실행을 빠르게 할 수도 있다.
- 특정 메모리 주소는 일반 메모리가 아닌 장치 레지스터가 될 수 있다.
- C++ 11은 std::atomic<>이라는 멀티 스레드 환경에서 선형 메모리처럼 작동하는 마법 주문을 제공한다.  
  일부 개발자는 volatile이 이러한 일을 한다고 생각하지만 잘못 알고 있는 것이다.

-> 운영체제도 거짓말을 한다. 프로그램이 컴퓨터에서 단독으로 사용되고, 물리 메모리는 무한하며, 프로그램 스레드를 실행할 수 있는 프로세서가 무한으로 있다고 한다.
***
## 2.2 컴퓨터의 진실
-> 실제 컴퓨터의 메모리 하드웨어는 명령 실행 속도보다 매우 느리고, 메모리는 실제로 바이트 단위로 접근하지 않으며 동일한 셀로 구성된 간단한 선형 배열이 아니며 유한한 용량을 가진다.  

-> 최신 프로세서는 하나의 명령어를 읽기, 해석, 실행, 결과 반영 4단계로 이루어지는데, 하나의 CPU에서 읽기, 해석, 실행, 결과 반영을 동시에 할 수 있기 떄문에 해석하는 동안 다른 명령어를 읽을 수도 있다. 

-> 즉, 명령어가 여러개 실행 될 수 있다. 명령 주소가 여러개 될 수 있다.

### 2.2.1 메모리는 느립니다.
- 메인 메모리는 마이크로프로세서에 있는 게이트와 레지스터보다 매우 느리다.  
  프로세서가 메인 메모리에서 단일 데이터 워드를 가져오는 시간에 명령어 수백 개를 실행할 수 있다.
- 메모리에 접근하는 비용은 프로세서의 다른 비용들(명령 실행 비용을 포함)을 압도한다. (메모리 장벽)
### 2.2.2 메모리는 워드 단위로 접근합니다.
- 컴퓨터는 대용량 데이터를 한꺼번에 가져와 속도가 느린 물리 메모리를 보완하는 일이 많다.  
  (데스크톱급 프로세서는 한번에 64바이트를 가져올 수 있다.)
- 워드 사이즈 데이터가 워드 단위로 있지 않고 워드 단위 사이에 있는 경우 메모리 로딩을 위해서는 2배의 시간이 걸린다.  
  이를 정렬되지 않은 메모리 접근(unaligned memory access)이라고 한다.
- C++ 컴파일러는 구조체 내 각 필드의 시작 주소가 필드 크기의 배수인 바이트 주소가 되도록 정렬한다.  
  이는 사용되지 않는 데이터가 구조체에 포함되어 '구멍'이 생기는 문제를 초래한다.  
  구조체에서 데이터 필드의 크기와 순서에 주의를 기울인다면, 구조체의 크기를 최소화 하면서도 정렬된 상태로 유지할 수 있다.
### 2.2.3 메모리마다 접근 속도가 다릅니다.
- 속도가 느린 메모리를 보완하기 위해 많은 컴퓨터에서는 프로세서와 매우 가까운 곳에 속도가 빠른 임시 저장소 캐시 메모리가 있다.
- 필요한 데이터가 여러 단계의 캐시 메모리(L1,L2,L3), 메인 메모리, 디스크상 가상 메모리 페이지 중 어디에 있는 지에 따라 접근하는데 필요한 시간이 다르다.  
  명령 수행 속도를 높여도 캐시 메모리 적중률이 낮으면 결국 느리게 동작한다.
- 캐시 메모리 정책
> - 캐시에 없는 데이터를 가져와야할 때, 현재 캐시에 있는 데이터 중 일부를 삭제해야 한다. 일반적으로 가장 오래전에 사용된 데이터를 삭제한다.  
>    '즉, 적게 사용하는 메모리 위치보다 많이 사용하는 메모리 위치에 더 빠르게 접근할수 있다.'  
> - 캐시에 없는 데이터를 1바이트만 읽어도 근처에 있는 바이트가 함께 캐싱된다.  
>    '즉, 인접한 위치의 메모리가 멀리 떨어진 곳의 메모리보다 (평균적으로) 더 빨리 접근할 수 있다.'
> - C++에서 반복문 코드 블록은 명령어를 자주 실행하고, 서로 근처에 있기 때문에 더 빠르게 실행되고, 캐시 적중률이 높다.  
>   반면 함수 호출 코드 블록이 여기저기 돌아다니며 작업을 수행하는 if문은 코드는 각 부분이 적게 사용되고 데이터가 근처에 있지 않기 때문에 느리게 동작한다.
### 2.2.4 워드를 저장하는 방법에는 빅 엔디언과 리틀 엔디언이 있습니다.
### 2.2.5 메모리는 항정된 자원입니다.
- 운영체제는 무한한 메모리라는 환상을 유지하기 위해 크기에 맞지 않는 데이터를 디스크의 파일로 저장하기도 한다.  
  이를 가상 메모리라고 한다. 가상 메모리는 물리 메모리가 더 많이 있다는 환상을 만들어 준다. 그리고 느리다.
- 캐시 메모리 용량을 늘려 속도를 높이기에는 비용이 너무 많이 든다.
- 크기가 큰 프로그램이 여러 메모리 위치에서 분산 접근을 하는 경우, 프로그램에 즉시 사용할 데이터를 보유하기에 메모리 공간이 부족할 수 있다.  
  이 때문에 페이징 스래싱(page thrashing)이라는 일종의 성능 붕괴가 일어난다.
> - 실제 필요한 데이터가 물리 메모리에 없을 경우 이를 가상 메모리에서 가져오는데, 이 상황을 페이지 폴트(page fault)라고 한다.  
   페이지 스레싱은 CPU가 실제 수행해야 할 작업보다 페이지 폴트를 처리하는데 더 많은 시간을 할애하는 문제를 뜻한다.
### 2.2.6 명령 실행은 느립니다.
- 현대의 데스크톱 컴퓨터는 아무 방해도 받지 않을 경우 놀라운 속도로 명령을 실행한다. (몇백 피코초 단위)  
  하지만 그렇다고 해서 각 명령을 수행하는 시간이 피코초 단위라는 것은 아니다.
- 프로세서에는 동시 작업 중인 명령 '파이프라인'이 포함되어 있다.  
  파이프라인으로 명령이 작동하고, 디코드되고, 인수를 취하고, 계산을 수행하고, 결과를 저장한다.  
  프로세사가 강력할수록 파이프라인이 복잡해져 명령 실행을 십수 단계로 나누기 때문에 더 많은 명령을 동시에 처리할 수 있다.
- 문제는 명령 A와 B가 있을 때, 명령 A의 결과가 있어야 명령 B가 실행이 가능하면 동시에 명령어 수행이 불가능하다.  
  이를 파이프라인 스톨(pipeline stall)이라 하며, 파이프라인 스톨이 자주 발생할수록 현대 프로세서의 장점이 무산된다.
### 2.2.7 컴퓨터는 의사 결정을 잘 하지 못합니다.
- 컴퓨터는 대부분 명령을 수행한 후에 다음 메모리 주소의 명령을 수행하며 실행한다.  
  보통 다음 명령어는 이미 캐시에 있다. 첫 번째 파이프라인 단계가 사용가능해지면 파이프라인에 명령을 연속해서 바로 공급할 수 있다.
- 문제는 실행의 흐름을 변경하는 명령(transfer-of-control)은 다르다.  
  점프나 함수 호출 같은 명령어들은 실행 주소를 임의의 새 값으로 변경한다.  
  이로인해 다음 명령은 점프 명령을 처리하는 중 실행 주소가 갱신될 때까지 메모리에서 잠시 동안 데이터를 읽을 수 없으며 파이프라인에도 놓일 수 없다.  
  (새 실행 주소의 메모리 워드는 캐시에 있을 가능성도 적다. 캐시 적중률 하락 + 파이프스톨)  
  즉, 의사 결정은 계산보다 느리고 이는 최적화의 중요성을 보여준다.
### 2.2.8 프로그램 실행에는 여러 스트림이 있습니다.
- 오늘날 운영체제에서 실행되는 모든 프로그램은 동시에 실행 중인 다른 프로그램과 컴퓨터 자원을 차지하려고 경쟁한다.  
  (네트워크 인터페이스, 디스크, 사운드 장치, 가속도계, 온도계와 같은 주변 장치도 포함된다.)
- 성능 향상을 위해서는 프로그램이 컴퓨터의 시동 시간이나 최고 부하 시간에 실행될 때, 즉 부하 상태에서 성능을 측정해야 한다.  
  (많은 프로그램이 동시에 시작되어 메모리와 디스크를 놓고 경쟁하면 예외도 많이 발생된다. 버그...)
- 운영체제에는 코어 개수 이상의 프로세서가 실행 중이며, 짧은 시간 동안 프로세서를 실행하고 다른 프로세서(스레드)로 콘텍스트 스위칭(context switching)을 한다.  
> -> 콘텍스트 스위칭은 기존 실행 중인 프로세서의 정보를 물리 메모리로 전송(flush)시키고 다음 실행할 프로세서의 물리 메모리 데이터를 다시 불러오는 동작을 한다.  
     조금 더 자세히 보자면, 사용 중인 데이터는 물리 메모리에 저장하고 레지스터 정보는 물리-가상 메모리 페이지 레지스터에 저장된다.  
     그 후 새로운 프로세서의 물리-가상 메모리 페이지 레지스터를 불러오고, 비어있는 캐시를 채우기 위해 초기에 실행 속도가 느려질 수 있으며 메모리 경합이 발생한다.
 - 멀티 코어 프로세서의 실행 유닛과 연관된 캐시 메모리는 성능 향상을 위해 거의 서로 독립적으로 작동한다.  
   하지만 모든 실행 유닛은 동일한 메인 메모리를 공유한다.  
   이로 인해서 한 실행 유닛이 값을 쓸 때, 다른 실행 유닛은 그 값을 볼 수 없다. (메인 메모리에서 캐시 메모리로 이동하기 때문) 
> -> 여러 실행 유닛이 있는 경우, 하나의 실행 유닛이 메인 메모리를 가져다 사용하고 반환한다면 다른 실행 유닛은 변경 전에 볼 수도 있고 변경 후에 볼 수도 있다.  
     즉, 정상적인 동작을 보장하기 어렵다. 이를 막기 위해서는 특수한 동기화 명령어를 사용해야하며 이는 스레드 간 공유하는 데이터에 접근하는 속도를 훨씬 느리게 만든다.
### 2.2.9 운영체제 기능을 호출하는 비용은 높습니다.
- 운영체제는 프로그램 A가 프로그램 B에 속하는 물리 메모리를 읽거나, 쓰거나, 실행할 수 없게 관리한다.
- 운영체제(OS 커널)는 모든 프로그램이 속한 메모리에 접근할 수 있어야 한다.
***
## 2.3 C++도 거짓말을 합니다.
-> 사용자가 실행하는 컴퓨터가 간단하고 일관된 구조를 가졌다고 거짓말을 한다.  
   이를 대가로 사용자가 마이크로프로세서 장치의 모든 세부 사항을 몰라도 프로그래밍할 수 있게 해준다.
### 2.3.1 문장의 비용이 똑같이 높지는 않습니다.
- 같은 대입 모양도 구조체를 대입하는지 Primitive type 변수를 대입하는지에 따라 계산양이 다르다.  
  ex) 대입하는 메모리의 크기도 다를 뿐더러 생성자까지 호출된다면 더욱 달라진다.
- 산술 연산자와 비교 연산자도 오버로드 가능하기 때문에 계산 비용이 다르다.
### 2.3.2 문장은 순서대로 실행되지 않습니다.
- 컴파일러가 성능을 향상하려고 내부에서 문장을 재정렬하고 때로는 순서를 변경한다.
***
## 2.4 마치며
1. 메모리 접근 비용은 프로세서의 다른 비용을 압도한다.
2. 정렬되지 않은 메모리에 접근하는 시간은 모든 바이트가 동일한 워드에 있을 때보다 2배 오래 걸린다.
3. 많이 사용하는 메모리 위치는 적게 사용하는 메모리 위치보다 빨리 접근할 수 있다.
4. 인덥한 위치에 있는 메모리는 인접하지 않은 위치에 있는 메모리보다 더 빨리 접근할 수 있다.
5. 캐싱 때문에 전체 프로그램의 콘텍스트에서 실행되는 함수는 테스트 하네스에서 실행되는 동일한 함수보다 느리게 실행될 수 있다.
6. 실행 스레드 간 공유하는 데이터에 접근하는 속도는 공유하지 않는 데이터에 접근하는 것보다 훨씨 느리다.
7. 계산은 의사 결정보다 빠르다.
8. 모든 프로그램은 다른 프로그램들과 컴퓨터 자원을 놓고 경쟁한다.
9. 프로그램이 시동 시간이나 최고 부하 시간에 실행되어야 한다면, 해당 프로그램의 성능은 해당 부하 상태에서 측정해야 한다.
10. 모든 대입문, 함수 인수 초기화, 함수 반환문은 생성자를 호출하며, 그 생성자가 얼마나 많은 코드를 가지고 있는지 알 수 없다.
11. 일부 문장은 많은 양의 계산을 숨긴다. 문장의 형태로는 비용이 얼마나 드는지 알 수 없다.
12. 동기화 코드는 동시에 실행 가능한 스레드가 데이터를 공유할 때 얻을 수 있는 동시성을 줄인다.